(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{115:function(e,n,t){"use strict";t.r(n),t.d(n,"MDXContext",(function(){return d})),t.d(n,"MDXProvider",(function(){return u})),t.d(n,"mdx",(function(){return f})),t.d(n,"useMDXComponents",(function(){return m})),t.d(n,"withMDXComponents",(function(){return l}));var a=t(0),o=t.n(a);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(){return(r=Object.assign||function(e){for(var n=1;n<arguments.length;n++){var t=arguments[n];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(e[a]=t[a])}return e}).apply(this,arguments)}function c(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?c(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):c(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function p(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var d=o.a.createContext({}),l=function(e){return function(n){var t=m(n.components);return o.a.createElement(e,r({},n,{components:t}))}},m=function(e){var n=o.a.useContext(d),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},u=function(e){var n=m(e.components);return o.a.createElement(d.Provider,{value:n},e.children)},h={inlineCode:"code",wrapper:function(e){var n=e.children;return o.a.createElement(o.a.Fragment,{},n)}},b=o.a.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,r=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),d=m(t),l=a,u=d["".concat(r,".").concat(l)]||d[l]||h[l]||i;return t?o.a.createElement(u,s(s({ref:n},c),{},{components:t})):o.a.createElement(u,s({ref:n},c))}));function f(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,r=new Array(i);r[0]=b;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c.mdxType="string"==typeof e?e:a,r[1]=c;for(var p=2;p<i;p++)r[p]=t[p];return o.a.createElement.apply(null,r)}return o.a.createElement.apply(null,t)}b.displayName="MDXCreateElement"},44:function(e,n,t){"use strict";t.r(n),t.d(n,"frontMatter",(function(){return r})),t.d(n,"metadata",(function(){return c})),t.d(n,"rightToc",(function(){return s})),t.d(n,"default",(function(){return d}));var a=t(3),o=t(8),i=(t(0),t(115)),r={title:"Pre-annotations"},c={unversionedId:"kognic-io/pre_annotations",id:"kognic-io/pre_annotations",isDocsHomePage:!1,title:"Pre-annotations",description:"This feature is in an alpha stage and might be subject to changes",source:"@site/docs/kognic-io/pre_annotations.md",slug:"/kognic-io/pre_annotations",permalink:"/api/docs/kognic-io/pre_annotations",editUrl:"https://github.com/annotell/public-docs/docs-src/docs/kognic-io/pre_annotations.md",version:"current",sidebar:"docs",previous:{title:"Working with Inputs",permalink:"/api/docs/kognic-io/working_with_inputs"},next:{title:"Motion Compensation for Multi-Lidar Setups",permalink:"/api/docs/kognic-io/inputs/lidars_with_imu_data"}},s=[{value:"Creating pre-annotations using the kognic-io client",id:"creating-pre-annotations-using-the-kognic-io-client",children:[{value:"1. Creating a scene",id:"1-creating-a-scene",children:[]},{value:"2. Uploading an OpenLabel annotation",id:"2-uploading-an-openlabel-annotation",children:[]},{value:"3. Create the input",id:"3-create-the-input",children:[]}]},{value:"Supported pre-annotation features",id:"supported-pre-annotation-features",children:[{value:"Geometries",id:"geometries",children:[]},{value:"Attributes",id:"attributes",children:[]},{value:"Frames",id:"frames",children:[]},{value:"Streams",id:"streams",children:[]},{value:"Example pre-annotation",id:"example-pre-annotation",children:[]}]}],p={rightToc:s};function d(e){var n=e.components,t=Object(o.a)(e,["components"]);return Object(i.mdx)("wrapper",Object(a.default)({},p,t,{components:n,mdxType:"MDXLayout"}),Object(i.mdx)("div",{className:"admonition admonition-caution alert alert--warning"},Object(i.mdx)("div",{parentName:"div",className:"admonition-heading"},Object(i.mdx)("h5",{parentName:"div"},Object(i.mdx)("span",{parentName:"h5",className:"admonition-icon"},Object(i.mdx)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"},Object(i.mdx)("path",{parentName:"svg",fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"}))),"caution")),Object(i.mdx)("div",{parentName:"div",className:"admonition-content"},Object(i.mdx)("p",{parentName:"div"},"This feature is in an alpha stage and might be subject to changes"))),Object(i.mdx)("p",null,"Pre-annotations have many uses in ground-truth production. The pre-annotations feature allows information about the objects already known to be present in an input to be specified. Please reach out to our Advisory Services team to see how they can best be used for your use-case."),Object(i.mdx)("p",null,"The Kognic platform supports uploading pre-annotations in the OpenLabel format using the ",Object(i.mdx)("a",{parentName:"p",href:"https://pypi.org/project/kognic-openlabel"},"kognic-openlabel package")),Object(i.mdx)("h2",{id:"creating-pre-annotations-using-the-kognic-io-client"},"Creating pre-annotations using the kognic-io client"),Object(i.mdx)("p",null,"There are 3 steps that are needed in order to create pre-annotations in the Kognic platform."),Object(i.mdx)("ol",null,Object(i.mdx)("li",{parentName:"ol"},"Create a scene by uploading all the needed data"),Object(i.mdx)("li",{parentName:"ol"},"Upload an OpenLabel annotation as a pre-annotation"),Object(i.mdx)("li",{parentName:"ol"},"Create an input from the scene")),Object(i.mdx)("h3",{id:"1-creating-a-scene"},"1. Creating a scene"),Object(i.mdx)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.mdx)("div",{parentName:"div",className:"admonition-heading"},Object(i.mdx)("h5",{parentName:"div"},Object(i.mdx)("span",{parentName:"h5",className:"admonition-icon"},Object(i.mdx)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},Object(i.mdx)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),Object(i.mdx)("div",{parentName:"div",className:"admonition-content"},Object(i.mdx)("p",{parentName:"div"},"The scene is a subset of the input, specifically refering to the data, such as images or pointclouds.\nAn input is what is created when this data is ready to be annotated."))),Object(i.mdx)("p",null,'The interface for creating just a scene, without an input, is the same as we are familiar with.\nThe exception is that by not providing a project or a batch in the function call, the scene will be "dangling" until deemed ready for annotation'),Object(i.mdx)("pre",null,Object(i.mdx)("code",{parentName:"pre",className:"language-python",metastring:"reference",reference:!0},"https://github.com/annotell/annotell-python/blob/master/kognic-io/examples/lidars_and_cameras_seq_with_pre_annotations.py#L82-L83\n")),Object(i.mdx)("h3",{id:"2-uploading-an-openlabel-annotation"},"2. Uploading an OpenLabel annotation"),Object(i.mdx)("p",null,"The pre-annotation can be uploaded to the Kognic platform once the scene has been created successfully."),Object(i.mdx)("p",null,"Load your OpenLabel annotation according to the documentation in ",Object(i.mdx)("inlineCode",{parentName:"p"},"kognic-openlabel")," and upload it to the Kognic platform as such:"),Object(i.mdx)("pre",null,Object(i.mdx)("code",{parentName:"pre",className:"language-python"},"client.pre_annotation.create(\n    scene_uuid=scene_response.input_uuid, # from step 1\n    pre_annotation=OpenLabelAnnotation(...), \n    dryrun=dryrun\n)\n")),Object(i.mdx)("h3",{id:"3-create-the-input"},"3. Create the input"),Object(i.mdx)("p",null,"When the scene and pre-annotation have been successfully created, the input can be created.\nThis will add it to the latest open batch in a project, or the specific batch that's specified,\nand be ready for annotation with the pre-annotation present."),Object(i.mdx)("pre",null,Object(i.mdx)("code",{parentName:"pre",className:"language-python"},"client.lidars_and_cameras_sequence.create_from_scene(\n    scene_uuid=scene_response.input_uuid, # from step 1\n    annotation_types=annotation_types,\n    project=project,\n    dryrun=dryrun\n)\n")),Object(i.mdx)("h2",{id:"supported-pre-annotation-features"},"Supported pre-annotation features"),Object(i.mdx)("h3",{id:"geometries"},"Geometries"),Object(i.mdx)("ul",null,Object(i.mdx)("li",{parentName:"ul"},"Cuboid (",Object(i.mdx)("inlineCode",{parentName:"li"},"cuboid"),")"),Object(i.mdx)("li",{parentName:"ul"},"2D bounding box (",Object(i.mdx)("inlineCode",{parentName:"li"},"bbox"),")")),Object(i.mdx)("p",null,"Note that all geometries should be specified under frames rather than in the root of the pre-annotation."),Object(i.mdx)("h3",{id:"attributes"},"Attributes"),Object(i.mdx)("ul",null,Object(i.mdx)("li",{parentName:"ul"},"Text"),Object(i.mdx)("li",{parentName:"ul"},"Num"),Object(i.mdx)("li",{parentName:"ul"},"Boolean")),Object(i.mdx)("p",null,"At the moment only attributes for the objects are supported, i.e. geometry specific ones are not (apart from the ",Object(i.mdx)("inlineCode",{parentName:"p"},"stream"),"\nproperty). Attributes can be static (specified in the ",Object(i.mdx)("inlineCode",{parentName:"p"},"objects")," key) or dynamic (specified in the ",Object(i.mdx)("inlineCode",{parentName:"p"},"object_data")," for the\nobject in the frame) and must be allowed by the ",Object(i.mdx)("a",{parentName:"p",href:"/api/docs/key_concepts#task-definition"},"task definition"),", if one exists\nwhen creating an input from the scene."),Object(i.mdx)("h3",{id:"frames"},"Frames"),Object(i.mdx)("p",null,"Every pre-annotation must contain frames with unique timestamps that are among the ones specified in the scene. The\nreason for this is that the timestamps are used to map the frame in the pre-annotation to the correct frame in the scene.\nIn the static case, one frame should be used with timestamp 0."),Object(i.mdx)("h3",{id:"streams"},"Streams"),Object(i.mdx)("p",null,"Every geometry must have the ",Object(i.mdx)("inlineCode",{parentName:"p"},"stream")," property specified. This property determines which stream (or sensor) that the\ngeometry appears in. It is important that the stream is among the ones specified in the scene and of the same type, for\nexample ",Object(i.mdx)("inlineCode",{parentName:"p"},"camera")," or ",Object(i.mdx)("inlineCode",{parentName:"p"},"lidar"),"."),Object(i.mdx)("h3",{id:"example-pre-annotation"},"Example pre-annotation"),Object(i.mdx)("pre",null,Object(i.mdx)("code",{parentName:"pre",className:"language-json"},'{\n  "openlabel": {\n    "frame_intervals": [],\n    "frames": {\n      "0": {\n        "frame_properties": {\n          "timestamp": 0,\n          "external_id": "0"\n        },\n        "objects": {\n          "1232b4f4-e3ca-446a-91cb-d8d403703df7": {\n            "object_data": {\n              "cuboid": [\n                {\n                  "attributes": {\n                    "text": [\n                      {\n                        "name": "stream",\n                        "val": "LIDAR1"\n                      }\n                    ]\n                  },\n                  "name": "cuboid-89ac8a2b",\n                  "val": [\n                    2.079312801361084,\n                    -18.919870376586914,\n                    0.3359137773513794,\n                    -0.002808041640852679,\n                    0.022641949116037438,\n                    0.06772797660868829,\n                    0.9974429197838155,\n                    1.767102435869269,\n                    4.099334155319101,\n                    1.3691029802958168\n                  ]\n                }\n              ]\n            }\n          }\n        }\n      }\n    },\n    "metadata": {\n      "schema_version": "1.0.0"\n    },\n    "objects": {\n      "1232b4f4-e3ca-446a-91cb-d8d403703df7": {\n        "name": "1232b4f4-e3ca-446a-91cb-d8d403703df7",\n        "object_data": {\n          "text": [\n            {\n              "name": "color",\n              "val": "red"\n            }\n          ]\n        },\n        "type": "PassengerCar"\n      }\n    },\n    "relations": {},\n    "streams": {\n      "LIDAR1": {\n        "description": "",\n        "type": "lidar"\n      }\n    },\n    "tags": {}\n  }\n}\n')))}d.isMDXComponent=!0}}]);