"use strict";(self.webpackChunkkognic_sdk_docs=self.webpackChunkkognic_sdk_docs||[]).push([[614],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>g});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function a(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=o.createContext({}),l=function(e){var t=o.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=l(e.components);return o.createElement(p.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,p=e.parentName,c=a(e,["components","mdxType","originalType","parentName"]),d=l(n),m=r,g=d["".concat(p,".").concat(m)]||d[m]||u[m]||i;return n?o.createElement(g,s(s({ref:t},c),{},{components:n})):o.createElement(g,s({ref:t},c))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,s=new Array(i);s[0]=m;var a={};for(var p in t)hasOwnProperty.call(t,p)&&(a[p]=t[p]);a.originalType=e,a[d]="string"==typeof e?e:r,s[1]=a;for(var l=2;l<i;l++)s[l]=n[l];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2013:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var o=n(7462),r=(n(7294),n(3905));const i={title:"Uploading predictions"},s=void 0,a={unversionedId:"dataset-refinement/uploading-predictions",id:"dataset-refinement/uploading-predictions",title:"Uploading predictions",description:"Introduction",source:"@site/docs/dataset-refinement/uploading-predictions.md",sourceDirName:"dataset-refinement",slug:"/dataset-refinement/uploading-predictions",permalink:"/docs/dataset-refinement/uploading-predictions",draft:!1,editUrl:"https://github.com/annotell/public-docs/docs-src/docs/dataset-refinement/uploading-predictions.md",tags:[],version:"current",frontMatter:{title:"Uploading predictions"},sidebar:"docs",previous:{title:"Introduction",permalink:"/docs/dataset-refinement/introduction"},next:{title:"OpenLABEL format",permalink:"/docs/openlabel/openlabel-format"}},p={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Steps",id:"steps",level:2},{value:"1. Get the UUID of the dataset",id:"1-get-the-uuid-of-the-dataset",level:3},{value:"2. Get the UUID of the predictions group",id:"2-get-the-uuid-of-the-predictions-group",level:3},{value:"3. Upload predictions",id:"3-upload-predictions",level:3}],c={toc:l};function d(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,"In this example, we'll walk you through how to upload predictions using our API into an already existing dataset."),(0,r.kt)("p",null,"Before you begin. See ",(0,r.kt)("a",{parentName:"p",href:"./introduction#prerequisites"},"Prerequisites")),(0,r.kt)("h2",{id:"steps"},"Steps"),(0,r.kt)("h3",{id:"1-get-the-uuid-of-the-dataset"},"1. Get the UUID of the dataset"),(0,r.kt)("p",null,"You can either access the tool and copy the UUID following ",(0,r.kt)("inlineCode",{parentName:"p"},"dataset/")," in the URL, or utilize the datasets endpoint to\nget the uuid of the dataset:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'client.session.get(base_url + "datasets")\n')),(0,r.kt)("h3",{id:"2-get-the-uuid-of-the-predictions-group"},"2. Get the UUID of the predictions group"),(0,r.kt)("p",null,"In order to upload predictions, a prediction group needs to exist. Predictions can be organized into groups for any\npurpose imaginable. The UUID of an existing prediction group can be found in the URL after ",(0,r.kt)("inlineCode",{parentName:"p"},"predictions/")," or by using\nthe endpoint"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'client.session.get(base_url + f"/datasets/{datasetUuid}/predictions-groups")\n')),(0,r.kt)("h3",{id:"3-upload-predictions"},"3. Upload predictions"),(0,r.kt)("p",null,"For a small amount of predictions, synchronous calls might work"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nfrom kognic.auth.requests.auth_session import RequestsAuthSession\n\nbase_url = "https://dataset.app.kognic.com/v1/"\nclient = RequestsAuthSession()\n\npredictions_group_uuid = "..."\nopenlabel_content = {...}\ndata = {\n    "sceneUuid": "...",\n    "openlabelContent": openlabel_content,\n}\n\ntry:\n    response = client.session.post(\n        base_url + f"predictions-groups/{predictions_group_uuid}/predictions",\n        json=data\n    )\n    response.raise_for_status()\n    response_json = response.json()\n    print(f"Created prediction with uuid {response_json[\'data\']}")\nexcept requests.exceptions.RequestException as e:\n    msg = e.response.json()["message"]\n    print(f"Request error: {e}. with message: {msg}")\n')),(0,r.kt)("p",null,"For larger amounts of predictions, asynchronous calls are recommended. The following example uses the async client from\nthe ",(0,r.kt)("inlineCode",{parentName:"p"},"kognic-auth")," library to make 100 asynchronous calls:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import asyncio\n\nfrom kognic.auth.httpx.async_client import HttpxAuthAsyncClient\n\nbase_url = "https://dataset.app.kognic.com/v1/"\npredictions_group_uuid = "..."\nurl = base_url + f"predictions-groups/{predictions_group_uuid}/predictions"\nopenlabel_content = {...}\n\nMAX_CONNECTIONS = 10\n\n\nasync def upload_prediction(payload, session, sem):\n    async with sem:\n        response = await session.post(url, json=payload)\n        response.raise_for_status()\n        return response.json().get("data")\n\n\nasync def main(n_runs: int):\n    client = HttpxAuthAsyncClient()\n    session = await client.session\n\n    sem = asyncio.Semaphore(MAX_CONNECTIONS)\n    tasks = []\n    for i in range(n_runs):\n        payload = {"sceneUuid": "...", "openlabelContent": openlabel_content}\n        task = upload_prediction(payload, session, sem)\n        tasks.append(task)\n\n    responses = await asyncio.gather(*tasks)\n    await session.aclose()\n\n    print(responses)\n\n\nif __name__ == \'__main__\':\n    asyncio.run(main(100))\n')),(0,r.kt)("p",null,"Setting ",(0,r.kt)("inlineCode",{parentName:"p"},"MAX_CONNECTIONS")," to something bigger than 10 might not work and is not recommended."))}d.isMDXComponent=!0}}]);