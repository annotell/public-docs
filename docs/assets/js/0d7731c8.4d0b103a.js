"use strict";(self.webpackChunkkognic_sdk_docs=self.webpackChunkkognic_sdk_docs||[]).push([[7612],{4093:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>v,contentTitle:()=>_,default:()=>k,frontMatter:()=>j,metadata:()=>y,toc:()=>C});var t=a(4848),i=a(8453),o=a(1470),r=a(9365);function s(e){const n={code:"code",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from kognic.io.client import KognicIOClient\nfrom kognic.io.model.scene.cameras import Cameras, Frame\nfrom kognic.io.model.scene.resources import Image\n\n# 1. Build scene object\nscene = Cameras(\n    external_id="my-first-scene",\n    frame=Frame(images=[Image(filename="path/to/image.jpg")])\n)\n\n# 2. Upload scene\nclient = KognicIOClient()\nscene_uuid = client.cameras.create(scene).scene_uuid\nprint("Scene uploaded, got uuid:", scene_uuid)\n'})})}function c(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(s,{...e})}):s(e)}function l(e){const n={code:"code",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from kognic.io.client import KognicIOClient\nfrom kognic.io.model.scene.cameras import Cameras, Frame\nfrom kognic.io.model.scene.resources import Image\n\n# 1. Build scene object\nscene = Cameras(\n    external_id="my-first-scene",\n    frame=Frame(\n        images=[\n          # Sensor names must be unique\n          Image(sensor_name = "CAM1", filename="path/to/image1.jpg"),\n          Image(sensor_name = "CAM2", filename="path/to/image2.jpg")\n        ],\n    )\n)\n\n# 2. Upload scene\nclient = KognicIOClient()\nscene_uuid = client.cameras.create(scene).scene_uuid\nprint("Scene uploaded, got uuid:", scene_uuid)\n'})})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}function u(e){const n={code:"code",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from kognic.io.client import KognicIOClient\nfrom kognic.io.model.scene.cameras_sequence import CamerasSequence, Frame\nfrom kognic.io.model.scene.resources import Image\n\n# 1. Build scene object\nscene = CamerasSequence(\n    external_id="my-first-scene",\n    frames=[\n        # Relative timestamps must be unique and strictly increasing\n        Frame(\n            relative_timestamp=0,\n            frame_id="1",\n            images=[Image(filename="path/to/image1.jpg")],\n        ),\n        Frame(\n            relative_timestamp=100,\n            frame_id="2",\n            images=[Image(filename="path/to/image2.jpg")],\n        ),\n        Frame(\n            relative_timestamp=200,\n            frame_id="3",\n            images=[Image(filename="path/to/image3.jpg")],\n        ),\n    ]\n)\n\n# 2. Upload scene\nclient = KognicIOClient()\nscene_uuid = client.cameras_sequence.create(scene).scene_uuid\nprint("Scene uploaded, got uuid:", scene_uuid)\n'})})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(u,{...e})}):u(e)}function p(e){const n={code:"code",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from kognic.io.client import KognicIOClient\nfrom kognic.io.model.calibration import SensorCalibration, PinholeCalibration, LidarCalibration\nfrom kognic.io.model.scene.lidars_and_cameras import LidarsAndCameras, Frame\nfrom kognic.io.model.scene.resources import Image, PointCloud\n\nclient = KognicIOClient()\n\n# 1. Create calibration (see calibration section for more details)\nsensor_calibration = SensorCalibration(\n    external_id = my-first-calibration",\n    calibration = {\n        "CAM": PinholeCalibration(...),\n        "lidar": LidarCalibration(...)\n    }\n)\ncreated_calibration = client.calibration.create_calibration(sensor_calibration)\n\n# 2. Build scene object\nscene = LidarsAndCameras(\n    external_id=f"my-first-scene",\n    calibration_id = created_calibration.id,\n    frame=Frame(\n        images=[Image(sensor_name = "CAM", filename="path/to/image.jpg")],\n        point_clouds=[PointCloud(sensor_name = "lidar", filename="path/to/pointcloud.pcd")]\n    )\n)\n\n# 3. Upload scene\nscene_uuid = client.lidars_and_cameras.create(scene).scene_uuid\nprint("Scene uploaded, got uuid:", scene_uuid)\n'})})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}function f(e){const n={code:"code",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from kognic.io.client import KognicIOClient\nfrom kognic.io.model.calibration import SensorCalibration, PinholeCalibration, LidarCalibration\nfrom kognic.io.model.scene.lidars_and_cameras import LidarsAndCameras, Frame\nfrom kognic.io.model.scene.resources import Image, PointCloud\n\nclient = KognicIOClient()\n\n# 1. Create calibration (see calibration section for more details)\nsensor_calibration = SensorCalibration(\n    external_id = "my-first-calibration",\n    calibration = {\n        "CAM1": PinholeCalibration(...),\n        "CAM2": PinholeCalibration(...),\n        "lidar": LidarCalibration(...)\n    }\n)\ncreated_calibration = client.calibration.create_calibration(sensor_calibration)\n\n# 2. Build scene object\nscene = LidarsAndCameras(\n    external_id="my-first-scene",\n    calibration_id = created_calibration.id,\n    frame=Frame(\n        images=[\n          Image(sensor_name = "CAM1", filename="path/to/image1.jpg"),\n          Image(sensor_name = "CAM2", filename="path/to/image2.jpg"),\n        ],\n        point_clouds=[PointCloud(sensor_name = "lidar", filename="path/to/pointcloud.pcd")]\n    )\n)\n\n# 3. Upload scene\nclient = KognicIOClient()\nscene_uuid = client.lidars_and_cameras.create(scene).scene_uuid\nprint("Scene uploaded, got uuid:", scene_uuid)\n'})})}function g(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(f,{...e})}):f(e)}function b(e){const n={code:"code",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from kognic.io.client import KognicIOClient\nfrom kognic.io.model.calibration import SensorCalibration, PinholeCalibration, LidarCalibration\nfrom kognic.io.model.scene.lidars_and_cameras_sequence import LidarsAndCamerasSequence, Frame\nfrom kognic.io.model.scene.resources import Image, PointCloud\n\nclient = KognicIOClient()\n\n# 1. Create calibration (see calibration section for more details)\ncalibration = { "CAM": PinholeCalibration(...), "lidar": LidarCalibration(...) }\nsensor_calibration = SensorCalibration(\n    external_id = "my-first-calibration",\n    calibration = {\n        "CAM": PinholeCalibration(...),\n        "lidar": LidarCalibration(...)\n    }\n)\ncreated_calibration = client.calibration.create_calibration(sensor_calibration)\n\n# 2. Build scene object\nscene = LidarsAndCamerasSequence(\n    external_id="my-first-scene",\n    calibration_id = created_calibration.id,\n    frames=[\n        # Relative timestamps must be unique and strictly increasing\n        Frame(\n            relative_timestamp=0,\n            frame_id="1",\n            images=[Image(sensor_name = "CAM", filename="path/to/image1.jpg")],\n            point_clouds=[PointCloud(sensor_name = "lidar", filename="path/to/pointcloud1.pcd")]\n        ),\n        Frame(\n            relative_timestamp=100,\n            frame_id="2",\n            images=[Image(sensor_name = "CAM", filename="path/to/image2.jpg")],\n            point_clouds=[PointCloud(sensor_name = "lidar", filename="path/to/pointcloud2.pcd")]\n        ),\n        Frame(\n            relative_timestamp=200,\n            frame_id="3",\n            images=[Image(sensor_name = "CAM", filename="path/to/image3.jpg")],\n            point_clouds=[PointCloud(sensor_name = "lidar", filename="path/to/pointcloud3.pcd")]\n        ),\n    ]\n)\n\n# 3. Upload scene\nscene_uuid = client.lidars_and_cameras_sequence.create(scene).scene_uuid\nprint("Scene uploaded, got uuid:", scene_uuid)\n'})})}function x(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(b,{...e})}):b(e)}const j={id:"upload-your-first-scene",title:"Upload your First Scene",slug:"/upload-your-first-scene"},_="Upload your first scene",y={id:"upload-data/upload-your-first-scene",title:"Upload your First Scene",description:"When uploading raw data to the Kognic Platform, you need to do so in the form of a scene.",source:"@site/docs/upload-data/upload-your-first-scene.mdx",sourceDirName:"upload-data",slug:"/upload-your-first-scene",permalink:"/docs/upload-your-first-scene",draft:!1,unlisted:!1,editUrl:"https://github.com/annotell/public-docs/edit/master/docs-src/docs/upload-data/upload-your-first-scene.mdx",tags:[],version:"current",frontMatter:{id:"upload-your-first-scene",title:"Upload your First Scene",slug:"/upload-your-first-scene"},sidebar:"docs",previous:{title:"Key Concepts",permalink:"/docs/key-concepts"},next:{title:"View an Uploaded Scene",permalink:"/docs/upload-data/view-uploaded-scene"}},v={},C=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"What happens now?",id:"what-happens-now",level:2}];function w(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components},{Details:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"upload-your-first-scene",children:"Upload your first scene"}),"\n",(0,t.jsxs)(n.p,{children:["When uploading raw data to the Kognic Platform, you need to do so in the form of a ",(0,t.jsx)(n.strong,{children:"scene"}),".\nA scene is a collection of data from different sources, such as images, point clouds, and other sensor data.\nThis guide will walk you through the process of uploading your first scene, either in 2D (camera only) or 3D (camera and LiDAR/RADAR)."]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.p,{children:["You have successfully followed the ",(0,t.jsx)(n.a,{href:"/docs/getting-started/quickstart",children:"Quickstart"})," guide and have the ",(0,t.jsx)(n.code,{children:"kognic-io"})," library installed."]}),"\n",(0,t.jsxs)(a,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("h2",{style:{margin:"0px"},children:"Uploading a 2D scene"})}),(0,t.jsxs)(n.p,{children:["To upload a 2D scene, you need to have the raw images available on your local machine (or create a ",(0,t.jsx)(n.a,{href:"https://developers.kognic.com/docs/kognic-io/overview#data-from-callback",children:"callback"})," for remote data).\nIt is a two-step process:"]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Build the scene object in Python"}),"\n",(0,t.jsx)(n.li,{children:"Upload the scene object to the Kognic Platform"}),"\n"]}),(0,t.jsx)(n.p,{children:"Below follows examples for a few different cases."}),(0,t.jsxs)(o.A,{children:[(0,t.jsx)(r.A,{value:"one-image",label:"One Image",default:!0,children:(0,t.jsx)(c,{})}),(0,t.jsx)(r.A,{value:"multiple-images",label:"Multiple Images",default:!0,children:(0,t.jsx)(d,{})}),(0,t.jsx)(r.A,{value:"sequence",label:"Sequence",children:(0,t.jsx)(m,{})})]})]}),"\n",(0,t.jsxs)(a,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("h2",{style:{margin:"0px"},children:"Uploading a 2D/3D scene"})}),(0,t.jsxs)(n.p,{children:["To upload a 2D/3D scene, you need to have the raw images and point clouds available on your local machine (or create a ",(0,t.jsx)(n.a,{href:"https://developers.kognic.com/docs/kognic-io/overview#data-from-callback",children:"callback"})," for remote data).\nIn addition you need to have calibration data available.\nIt is a three-step process:"]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Create a ",(0,t.jsx)(n.a,{href:"./kognic-io/calibrations/overview",children:"calibration"})]}),"\n",(0,t.jsx)(n.li,{children:"Build the scene object in Python, referencing the calibration from the previous step"}),"\n",(0,t.jsx)(n.li,{children:"Upload the scene object to the Kognic Platform"}),"\n"]}),(0,t.jsx)(n.p,{children:"Below follows examples for a few different cases."}),(0,t.jsxs)(o.A,{children:[(0,t.jsx)(r.A,{value:"one-image-one-lidar",label:"One Image",default:!0,children:(0,t.jsx)(h,{})}),(0,t.jsx)(r.A,{value:"multiple-images",label:"Multiple Images",default:!0,children:(0,t.jsx)(g,{})}),(0,t.jsx)(r.A,{value:"2d/3d-sequence",label:"Sequence",default:!0,children:(0,t.jsx)(x,{})})]}),(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["Multiple point clouds is also supported, but not shown in the examples above since that requires a bit more data.\nSee the ",(0,t.jsx)(n.a,{href:"/docs/kognic-io/scenes/lidars_with_imu_data",children:"Motion Compensation"})," section for more details."]})})]}),"\n",(0,t.jsxs)(a,{children:[(0,t.jsx)("summary",{children:(0,t.jsx)("h2",{style:{margin:"0px"},children:"Uploading using ZOD Data"})}),(0,t.jsxs)(n.p,{children:["We have exemplar code and a tutorial for uploading scenes using ",(0,t.jsx)(n.a,{href:"https://zod.zenseact.com/",children:"Zenseact Open Dataset (ZOD)"})," data, including 2D, 3D,\nand aggregated 3D scenes. ",(0,t.jsx)(n.a,{href:"./upload-data/upload-zod-data",children:"Check out the guide document and exemplar code here!"})]}),(0,t.jsx)(n.p,{children:"If you have the ZOD data downloaded, and have Kognic API credentials, the examples will run out of the box to create\nfunctional scenes!"})]}),"\n",(0,t.jsx)(n.h2,{id:"what-happens-now",children:"What happens now?"}),"\n",(0,t.jsxs)(n.p,{children:["The response given when creating the scene, the ",(0,t.jsx)(n.code,{children:"scene_uuid"}),", is used to refer to the scene in the future. You can now\ncheck the status of the scene via the Platform or the Python client."]}),"\n",(0,t.jsxs)(o.A,{children:[(0,t.jsxs)(r.A,{value:"platform",label:"Kognic Platform",default:!0,children:[(0,t.jsxs)(n.p,{children:["Go to the ",(0,t.jsx)(n.a,{href:"https://app.kognic.com/data-orchestration",children:"Data Orchestration tab"})," in the Kognic Platform and search for the scene by its UUID or use any other suitable search criteria.\nThe status is shown in a column in the scenes list."]}),(0,t.jsxs)(n.p,{children:["Note that you may need to contact Kognic to get access to ",(0,t.jsx)(n.em,{children:"Data Orchestration"})," in case you do not see it."]})]}),(0,t.jsxs)(r.A,{value:"python",label:"Python",default:!0,children:[(0,t.jsxs)(n.p,{children:["Use the ",(0,t.jsx)(n.code,{children:"get_scenes_by_uuids"})," method to get the scene object from its UUID:"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"scene = client.scene.get_scenes_by_uuids([scene_uuid])[0]\n"})}),(0,t.jsx)(n.p,{children:"The scene object will contain the status of the scene."}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'print(f"Scene {scene.uuid} has status {scene.status}")\n'})})]})]}),"\n",(0,t.jsxs)(n.p,{children:["You may see the scene initially in the ",(0,t.jsx)(n.em,{children:"processing"})," state while Kognic performs a little background processing, or in the\n",(0,t.jsx)(n.em,{children:"ready"})," or ",(0,t.jsx)(n.em,{children:"failed"})," state after processing completes."]})]})}function k(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(w,{...e})}):w(e)}},9365:(e,n,a)=>{a.d(n,{A:()=>r});a(6540);var t=a(8215);const i={tabItem:"tabItem_Ymn6"};var o=a(4848);function r(e){let{children:n,hidden:a,className:r}=e;return(0,o.jsx)("div",{role:"tabpanel",className:(0,t.A)(i.tabItem,r),hidden:a,children:n})}},1470:(e,n,a)=>{a.d(n,{A:()=>v});var t=a(6540),i=a(8215),o=a(3104),r=a(6347),s=a(205),c=a(7485),l=a(1682),d=a(9466);function u(e){return t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function m(e){const{values:n,children:a}=e;return(0,t.useMemo)((()=>{const e=n??function(e){return u(e).map((e=>{let{props:{value:n,label:a,attributes:t,default:i}}=e;return{value:n,label:a,attributes:t,default:i}}))}(a);return function(e){const n=(0,l.X)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,a])}function p(e){let{value:n,tabValues:a}=e;return a.some((e=>e.value===n))}function h(e){let{queryString:n=!1,groupId:a}=e;const i=(0,r.W6)(),o=function(e){let{queryString:n=!1,groupId:a}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:n,groupId:a});return[(0,c.aZ)(o),(0,t.useCallback)((e=>{if(!o)return;const n=new URLSearchParams(i.location.search);n.set(o,e),i.replace({...i.location,search:n.toString()})}),[o,i])]}function f(e){const{defaultValue:n,queryString:a=!1,groupId:i}=e,o=m(e),[r,c]=(0,t.useState)((()=>function(e){let{defaultValue:n,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!p({value:n,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const t=a.find((e=>e.default))??a[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:o}))),[l,u]=h({queryString:a,groupId:i}),[f,g]=function(e){let{groupId:n}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(n),[i,o]=(0,d.Dv)(a);return[i,(0,t.useCallback)((e=>{a&&o.set(e)}),[a,o])]}({groupId:i}),b=(()=>{const e=l??f;return p({value:e,tabValues:o})?e:null})();(0,s.A)((()=>{b&&c(b)}),[b]);return{selectedValue:r,selectValue:(0,t.useCallback)((e=>{if(!p({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);c(e),u(e),g(e)}),[u,g,o]),tabValues:o}}var g=a(2303);const b={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=a(4848);function j(e){let{className:n,block:a,selectedValue:t,selectValue:r,tabValues:s}=e;const c=[],{blockElementScrollPositionUntilNextRender:l}=(0,o.a_)(),d=e=>{const n=e.currentTarget,a=c.indexOf(n),i=s[a].value;i!==t&&(l(n),r(i))},u=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const a=c.indexOf(e.currentTarget)+1;n=c[a]??c[0];break}case"ArrowLeft":{const a=c.indexOf(e.currentTarget)-1;n=c[a]??c[c.length-1];break}}n?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":a},n),children:s.map((e=>{let{value:n,label:a,attributes:o}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:t===n?0:-1,"aria-selected":t===n,ref:e=>c.push(e),onKeyDown:u,onClick:d,...o,className:(0,i.A)("tabs__item",b.tabItem,o?.className,{"tabs__item--active":t===n}),children:a??n},n)}))})}function _(e){let{lazy:n,children:a,selectedValue:i}=e;const o=(Array.isArray(a)?a:[a]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===i));return e?(0,t.cloneElement)(e,{className:"margin-top--md"}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:o.map(((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==i})))})}function y(e){const n=f(e);return(0,x.jsxs)("div",{className:(0,i.A)("tabs-container",b.tabList),children:[(0,x.jsx)(j,{...n,...e}),(0,x.jsx)(_,{...n,...e})]})}function v(e){const n=(0,g.A)();return(0,x.jsx)(y,{...e,children:u(e.children)},String(n))}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>s});var t=a(6540);const i={},o=t.createContext(i);function r(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);