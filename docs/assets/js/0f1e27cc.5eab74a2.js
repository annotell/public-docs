"use strict";(self.webpackChunkkognic_sdk_docs=self.webpackChunkkognic_sdk_docs||[]).push([[408],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function a(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},s=Object.keys(e);for(o=0;o<s.length;o++)n=s[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(o=0;o<s.length;o++)n=s[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=o.createContext({}),l=function(e){var t=o.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):a(a({},t),e)),n},c=function(e){var t=l(e.components);return o.createElement(p.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},g=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,s=e.originalType,p=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=l(n),g=r,m=d["".concat(p,".").concat(g)]||d[g]||u[g]||s;return n?o.createElement(m,a(a({ref:t},c),{},{components:n})):o.createElement(m,a({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=n.length,a=new Array(s);a[0]=g;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[d]="string"==typeof e?e:r,a[1]=i;for(var l=2;l<s;l++)a[l]=n[l];return o.createElement.apply(null,a)}return o.createElement.apply(null,n)}g.displayName="MDXCreateElement"},1405:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>l});var o=n(7462),r=(n(7294),n(3905));const s={title:"Uploading predictions"},a=void 0,i={unversionedId:"dataset-exploration/uploading-predictions",id:"dataset-exploration/uploading-predictions",title:"Uploading predictions",description:"Introduction",source:"@site/docs/dataset-exploration/uploading-predictions.md",sourceDirName:"dataset-exploration",slug:"/dataset-exploration/uploading-predictions",permalink:"/docs/dataset-exploration/uploading-predictions",draft:!1,editUrl:"https://github.com/annotell/public-docs/docs-src/docs/dataset-exploration/uploading-predictions.md",tags:[],version:"current",frontMatter:{title:"Uploading predictions"},sidebar:"docs",previous:{title:"The prediction format",permalink:"/docs/dataset-exploration/prediction-format"},next:{title:"Understand what your dataset contains",permalink:"/docs/dataset-exploration/understand-dataset-content"}},p={},l=[{value:"Introduction",id:"introduction",level:2},{value:"Steps",id:"steps",level:2},{value:"1. Get the UUID of the dataset",id:"1-get-the-uuid-of-the-dataset",level:3},{value:"2. Get the UUID of an existing predictions group",id:"2-get-the-uuid-of-an-existing-predictions-group",level:3},{value:"3. Upload predictions",id:"3-upload-predictions",level:3}],c={toc:l};function d(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,"In this example, we'll walk you through how to upload predictions using our API into an already existing dataset."),(0,r.kt)("p",null,"Before you begin: See ",(0,r.kt)("a",{parentName:"p",href:"./introduction#prerequisites"},"Prerequisites")," and learn about\nthe ",(0,r.kt)("a",{parentName:"p",href:"./prediction-format"},"prediction format"),"."),(0,r.kt)("h2",{id:"steps"},"Steps"),(0,r.kt)("p",null,"Create a new python file and import the following libraries:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nfrom kognic.auth.requests.auth_session import RequestsAuthSession\n\nbase_url = "https://dataset.app.kognic.com/v1/"\nclient = RequestsAuthSession()\n')),(0,r.kt)("h3",{id:"1-get-the-uuid-of-the-dataset"},"1. Get the UUID of the dataset"),(0,r.kt)("p",null,"You can either access the tool and copy the UUID following ",(0,r.kt)("inlineCode",{parentName:"p"},"dataset/")," in the URL, or utilize the datasets endpoint to\nget the uuid of the dataset:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'client.session.get(base_url + "datasets")\n')),(0,r.kt)("h3",{id:"2-get-the-uuid-of-an-existing-predictions-group"},"2. Get the UUID of an existing predictions group"),(0,r.kt)("p",null,"In order to upload predictions, a prediction group needs to exist. Predictions can be organized into groups for any\npurpose imaginable. The UUID of an existing prediction group can be found in the URL after ",(0,r.kt)("inlineCode",{parentName:"p"},"predictions/")," or by using\nthe endpoint"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'client.session.get(base_url + f"/datasets/{datasetUuid}/predictions-groups")\n')),(0,r.kt)("p",null,"You can also create a new prediction group using the following code snippet"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'path = base_url + f"/datasets/{datasetUuid}/predictions-groups"\nbody = {"name": "My predictions group", "description": "A description of my new predictions group"}\ntry:\n    response = client.session.post(path, json=body)\n    response.raise_for_status()\n    response_json = response.json()\n    print(f"Created predictions group with uuid {response_json[\'data\']}")\nexcept requests.exceptions.RequestException as e:\n    msg = e.response.text\n    print(f"Request error: {e}. {msg}")\n')),(0,r.kt)("h3",{id:"3-upload-predictions"},"3. Upload predictions"),(0,r.kt)("p",null,"For a small amount of predictions, synchronous calls might work"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nfrom kognic.auth.requests.auth_session import RequestsAuthSession\n\nbase_url = "https://dataset.app.kognic.com/v1/"\nclient = RequestsAuthSession()\n\npredictions_group_uuid = "..."\nopenlabel_content = {"openlabel": ...}\ndata = {\n    "sceneUuid": "...",\n    "openlabelContent": openlabel_content,\n}\n\ntry:\n    response = client.session.post(\n        base_url + f"predictions-groups/{predictions_group_uuid}/predictions",\n        json=data\n    )\n    response.raise_for_status()\n    response_json = response.json()\n    print(f"Created prediction with uuid {response_json[\'data\']}")\nexcept requests.exceptions.RequestException as e:\n    msg = e.response.text\n    print(f"Request error: {e}. {msg}")\n')),(0,r.kt)("p",null,"For larger amounts of predictions, asynchronous calls are recommended. The following example uses the async client from\nthe ",(0,r.kt)("inlineCode",{parentName:"p"},"kognic-auth")," library to make 100 asynchronous calls:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import asyncio\n\nfrom kognic.auth.httpx.async_client import HttpxAuthAsyncClient\n\nbase_url = "https://dataset.app.kognic.com/v1/"\npredictions_group_uuid = "..."\nurl = base_url + f"predictions-groups/{predictions_group_uuid}/predictions"\nopenlabel_content = {"openlabel": ...}\n\nMAX_CONNECTIONS = 10\n\n\nasync def upload_prediction(payload, session, sem):\n    async with sem:\n        response = await session.post(url, json=payload)\n        response.raise_for_status()\n        return response.json().get("data")\n\n\nasync def main(n_runs: int):\n    client = HttpxAuthAsyncClient()\n    session = await client.session\n\n    sem = asyncio.Semaphore(MAX_CONNECTIONS)\n    tasks = []\n    for i in range(n_runs):\n        payload = {"sceneUuid": "...", "openlabelContent": openlabel_content}\n        task = upload_prediction(payload, session, sem)\n        tasks.append(task)\n\n    responses = await asyncio.gather(*tasks)\n    await session.aclose()\n\n    print(responses)\n\n\nif __name__ == \'__main__\':\n    asyncio.run(main(100))\n')),(0,r.kt)("p",null,"Setting ",(0,r.kt)("inlineCode",{parentName:"p"},"MAX_CONNECTIONS")," to something bigger than 10 might not work and is not recommended."))}d.isMDXComponent=!0}}]);