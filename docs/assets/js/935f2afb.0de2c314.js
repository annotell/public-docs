"use strict";(self.webpackChunkkognic_sdk_docs=self.webpackChunkkognic_sdk_docs||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"category","label":"Kognic APIs","items":[{"type":"link","label":"Kognic APIs","href":"/docs/kognic-apis","docId":"kognic-apis"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Key Concepts","items":[{"type":"link","label":"Key Concepts","href":"/docs/","docId":"key_concepts"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Kognic IO","items":[{"type":"link","label":"Projects","href":"/docs/kognic-io/project","docId":"kognic-io/project"},{"type":"category","label":"Scenes","items":[{"type":"link","label":"Overview","href":"/docs/kognic-io/overview","docId":"kognic-io/overview"},{"type":"link","label":"Annotation Types","href":"/docs/kognic-io/annotation_types","docId":"kognic-io/annotation_types"},{"type":"category","label":"Scene Types","items":[{"type":"link","label":"Cameras","href":"/docs/kognic-io/scenes/cameras","docId":"kognic-io/scenes/cameras"},{"type":"link","label":"Lidars and Cameras","href":"/docs/kognic-io/scenes/lidars_and_cameras","docId":"kognic-io/scenes/lidars_and_cameras"},{"type":"link","label":"Cameras Sequence","href":"/docs/kognic-io/scenes/cameras_seq","docId":"kognic-io/scenes/cameras_seq"},{"type":"link","label":"Lidars and Cameras Sequence","href":"/docs/kognic-io/scenes/lidars_and_cameras_seq","docId":"kognic-io/scenes/lidars_and_cameras_seq"},{"type":"link","label":"Aggregated Lidars and Cameras Sequence","href":"/docs/kognic-io/scenes/aggregated_lidars_and_cameras_seq","docId":"kognic-io/scenes/aggregated_lidars_and_cameras_seq"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Motion Compensation","href":"/docs/kognic-io/scenes/lidars_with_imu_data","docId":"kognic-io/scenes/lidars_with_imu_data"},{"type":"link","label":"Scene Feature Flags","href":"/docs/kognic-io/feature_flags","docId":"kognic-io/feature_flags"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Annotations","items":[{"type":"link","label":"Pre-annotations","href":"/docs/kognic-io/pre_annotations","docId":"kognic-io/pre_annotations"},{"type":"link","label":"Downloading Annotations","href":"/docs/kognic-io/annotations","docId":"kognic-io/annotations"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Working with Scenes & Inputs","href":"/docs/kognic-io/working_with_scenes_and_inputs","docId":"kognic-io/working_with_scenes_and_inputs"},{"type":"category","label":"Calibrations","items":[{"type":"link","label":"Calibrations Overview","href":"/docs/kognic-io/calibrations/overview","docId":"kognic-io/calibrations/overview"},{"type":"link","label":"Lidar Calibrations","href":"/docs/kognic-io/calibrations/lidars","docId":"kognic-io/calibrations/lidars"},{"type":"link","label":"Standard Camera Calibrations","href":"/docs/kognic-io/calibrations/cameras-standard","docId":"kognic-io/calibrations/cameras-standard"},{"type":"link","label":"Custom Camera Calibrations","href":"/docs/kognic-io/calibrations/cameras-custom","docId":"kognic-io/calibrations/cameras-custom"}],"collapsed":true,"collapsible":true},{"type":"link","label":"Coordinate Systems","href":"/docs/kognic-io/coordinate_systems","docId":"kognic-io/coordinate_systems"},{"type":"link","label":"Errors","href":"/docs/kognic-io/error_handling","docId":"kognic-io/error_handling"},{"type":"link","label":"FAQ","href":"/docs/kognic-io/FAQ","docId":"kognic-io/FAQ"},{"type":"category","label":"Supported File Formats","items":[{"type":"link","label":"Images","href":"/docs/kognic-io/resources/images","docId":"kognic-io/resources/images"},{"type":"link","label":"Point clouds","href":"/docs/kognic-io/resources/pointclouds","docId":"kognic-io/resources/pointclouds"}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Dataset exploration","items":[{"type":"link","label":"Introduction","href":"/docs/dataset-exploration/introduction","docId":"dataset-exploration/introduction"},{"type":"link","label":"The prediction format","href":"/docs/dataset-exploration/prediction-format","docId":"dataset-exploration/prediction-format"},{"type":"link","label":"Uploading predictions","href":"/docs/dataset-exploration/uploading-predictions","docId":"dataset-exploration/uploading-predictions"}],"collapsed":true,"collapsible":true},{"type":"category","label":"OpenLABEL","items":[{"type":"link","label":"OpenLABEL format","href":"/docs/openlabel/openlabel-format","docId":"openlabel/openlabel-format"},{"type":"link","label":"The Python client","href":"/docs/openlabel/python-client","docId":"openlabel/python-client"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Migration Guide","items":[{"type":"link","label":"annotell-input-api to kognic-io","href":"/docs/a2k_migration_guide","docId":"a2k_migration_guide"}],"collapsed":true,"collapsible":true}]},"docs":{"a2k_migration_guide":{"id":"a2k_migration_guide","title":"annotell-input-api to kognic-io","description":"Overview","sidebar":"docs"},"dataset-exploration/introduction":{"id":"dataset-exploration/introduction","title":"Introduction","description":"The dataset API is in an early release stage and might be subject to changes.","sidebar":"docs"},"dataset-exploration/prediction-format":{"id":"dataset-exploration/prediction-format","title":"The prediction format","description":"Predictions use the OpenLabel format, which is expressed in JSON. This is the same format as the one used","sidebar":"docs"},"dataset-exploration/uploading-predictions":{"id":"dataset-exploration/uploading-predictions","title":"Uploading predictions","description":"Introduction","sidebar":"docs"},"dataset-refinement/introduction":{"id":"dataset-refinement/introduction","title":"Introduction","description":"This page has moved here"},"dataset-refinement/prediction-format":{"id":"dataset-refinement/prediction-format","title":"The prediction format","description":"This page has moved here"},"dataset-refinement/uploading-predictions":{"id":"dataset-refinement/uploading-predictions","title":"Uploading predictions","description":"This page has moved here"},"key_concepts":{"id":"key_concepts","title":"Key Concepts","description":"Kognic Platform Concepts","sidebar":"docs"},"kognic-apis":{"id":"kognic-apis","title":"Kognic APIs","description":"Overview of Kognic API usage including authentication","sidebar":"docs"},"kognic-io/annotation_types":{"id":"kognic-io/annotation_types","title":"Annotation Types","description":"Annotation Types are something that can be configured for a project either during or after","sidebar":"docs"},"kognic-io/annotations":{"id":"kognic-io/annotations","title":"Downloading Annotations","description":"Annotations are made available for each scene and annotation type as soon as they are quality assured","sidebar":"docs"},"kognic-io/calibrations/cameras-custom":{"id":"kognic-io/calibrations/cameras-custom","title":"Custom Camera Calibrations","description":"This feature is new in version 1.8.0 of kognic-io and some parts require optional dependencies. Run pip install kognic-io[wasm] to install it.","sidebar":"docs"},"kognic-io/calibrations/cameras-standard":{"id":"kognic-io/calibrations/cameras-standard","title":"Standard Camera Calibrations","description":"The Camera calibration format is based on OpenCVs format and","sidebar":"docs"},"kognic-io/calibrations/lidars":{"id":"kognic-io/calibrations/lidars","title":"Lidar Calibrations","description":"A LIDAR calibration is represented as a LidarCalibration object and consists of a position expressed with three coordinates and a rotation","sidebar":"docs"},"kognic-io/calibrations/overview":{"id":"kognic-io/calibrations/overview","title":"Calibrations Overview","description":"Scenes including both a 2D and 3D representation such as lidarsandcameras deal with data in a number of different","sidebar":"docs"},"kognic-io/coordinate_systems":{"id":"kognic-io/coordinate_systems","title":"Coordinate Systems","description":"Scenes such as lidarsandcameras_sequence need to be able to combine the data from different sensors and from","sidebar":"docs"},"kognic-io/error_handling":{"id":"kognic-io/error_handling","title":"Errors","description":"Dealing with Errors","sidebar":"docs"},"kognic-io/FAQ":{"id":"kognic-io/FAQ","title":"FAQ","description":"FAQ","sidebar":"docs"},"kognic-io/feature_flags":{"id":"kognic-io/feature_flags","title":"Scene Feature Flags","description":"To make the scene creation process more flexible we support optional feature flags that can be passed at scene creation time.","sidebar":"docs"},"kognic-io/overview":{"id":"kognic-io/overview","title":"Overview","description":"Different types of scenes","sidebar":"docs"},"kognic-io/pre_annotations":{"id":"kognic-io/pre_annotations","title":"Pre-annotations","description":"This feature is in an early release stage and might be subject to changes","sidebar":"docs"},"kognic-io/project":{"id":"kognic-io/project","title":"Projects","description":"Project","sidebar":"docs"},"kognic-io/resources/images":{"id":"kognic-io/resources/images","title":"Images","description":"The API allows uploading of annotation project related data such as images and point clouds. For images, we currently support two formats: png, jpg and webp.","sidebar":"docs"},"kognic-io/resources/pointclouds":{"id":"kognic-io/resources/pointclouds","title":"Point clouds","description":"The API allows uploading of annotation project related data such as images and point clouds. Kognic uses a potree format internally to represent and present point clouds, this means that uploaded point cloud data needs to be converted into this format before it can be used as scene in the system. We currently support automatic conversion of three formats: pcd, csv and las. The converter does not however exhaustively support all possible versions of these formats, see below for details of each format.","sidebar":"docs"},"kognic-io/scenes/aggregated_lidars_and_cameras_seq":{"id":"kognic-io/scenes/aggregated_lidars_and_cameras_seq","title":"Aggregated Lidars and Cameras Sequence","description":"This feature is new in version 1.1.5","sidebar":"docs"},"kognic-io/scenes/cameras":{"id":"kognic-io/scenes/cameras","title":"Cameras","description":"A Cameras  consists of a single frame of camera images, where the frame can contain between 1-9 images from different sensors. For more documentation on what each field corresponds to in the Cameras object please check the section related to Scene Overview.","sidebar":"docs"},"kognic-io/scenes/cameras_seq":{"id":"kognic-io/scenes/cameras_seq","title":"Cameras Sequence","description":"A CamerasSeq  consists of a sequence of camera images, where each frame can contain between 1-9 images from different sensors. For more documentation on what each field corresponds to in the CamerasSeq object please check the section related to Scene Overview.","sidebar":"docs"},"kognic-io/scenes/lidars_and_cameras":{"id":"kognic-io/scenes/lidars_and_cameras","title":"Lidars and Cameras","description":"A LidarsAndCameras  consists of a single frame which contains 1-9 cameras images as well as 1-20 point clouds. For more documentation on what each field corresponds to in the LidarsAndCameras object please check the section related to Scene Overview.","sidebar":"docs"},"kognic-io/scenes/lidars_and_cameras_seq":{"id":"kognic-io/scenes/lidars_and_cameras_seq","title":"Lidars and Cameras Sequence","description":"A LidarsAndCamerasSeq  consists of a sequence of camera images and lidar point clouds, where each frame consists","sidebar":"docs"},"kognic-io/scenes/lidars_with_imu_data":{"id":"kognic-io/scenes/lidars_with_imu_data","title":"Motion Compensation","description":"An inherent problem with labeling any lidar setup","sidebar":"docs"},"kognic-io/working_with_scenes_and_inputs":{"id":"kognic-io/working_with_scenes_and_inputs","title":"Working with Scenes & Inputs","description":"For detailed information about different scene modalities, check the Scene Types section.","sidebar":"docs"},"openlabel/openlabel-format":{"id":"openlabel/openlabel-format","title":"OpenLABEL format","description":"OpenLABEL is a standardized annotation format developed by ASAM.","sidebar":"docs"},"openlabel/python-client":{"id":"openlabel/python-client","title":"The Python client","description":"Using this schema we have developed a python client kognic-openlabel which makes it easier","sidebar":"docs"}}}')}}]);