"use strict";(self.webpackChunkkognic_sdk_docs=self.webpackChunkkognic_sdk_docs||[]).push([[408],{3905:(e,n,t)=>{t.d(n,{Zo:()=>l,kt:()=>m});var o=t(7294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)t=i[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)t=i[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var p=o.createContext({}),d=function(e){var n=o.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},l=function(e){var n=d(e.components);return o.createElement(p.Provider,{value:n},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},g=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,p=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),c=d(t),g=a,m=c["".concat(p,".").concat(g)]||c[g]||u[g]||i;return t?o.createElement(m,r(r({ref:n},l),{},{components:t})):o.createElement(m,r({ref:n},l))}));function m(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,r=new Array(i);r[0]=g;var s={};for(var p in n)hasOwnProperty.call(n,p)&&(s[p]=n[p]);s.originalType=e,s[c]="string"==typeof e?e:a,r[1]=s;for(var d=2;d<i;d++)r[d]=t[d];return o.createElement.apply(null,r)}return o.createElement.apply(null,t)}g.displayName="MDXCreateElement"},1405:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>r,default:()=>c,frontMatter:()=>i,metadata:()=>s,toc:()=>d});var o=t(7462),a=(t(7294),t(3905));const i={title:"Uploading predictions"},r=void 0,s={unversionedId:"dataset-exploration/uploading-predictions",id:"dataset-exploration/uploading-predictions",title:"Uploading predictions",description:"Introduction",source:"@site/docs/dataset-exploration/uploading-predictions.md",sourceDirName:"dataset-exploration",slug:"/dataset-exploration/uploading-predictions",permalink:"/docs/dataset-exploration/uploading-predictions",draft:!1,editUrl:"https://github.com/annotell/public-docs/docs-src/docs/dataset-exploration/uploading-predictions.md",tags:[],version:"current",frontMatter:{title:"Uploading predictions"},sidebar:"docs",previous:{title:"The prediction format",permalink:"/docs/dataset-exploration/prediction-format"},next:{title:"Understand what your dataset contains",permalink:"/docs/dataset-exploration/understand-dataset-content"}},p={},d=[{value:"Introduction",id:"introduction",level:2},{value:"Steps",id:"steps",level:2},{value:"1. Get the UUID of the dataset",id:"1-get-the-uuid-of-the-dataset",level:3},{value:"2. Get the UUID of an existing predictions group or create a new one",id:"2-get-the-uuid-of-an-existing-predictions-group-or-create-a-new-one",level:3},{value:"2.a Get the UUID of an existing predictions group",id:"2a-get-the-uuid-of-an-existing-predictions-group",level:4},{value:"2.b Creating a predictions group (optional)",id:"2b-creating-a-predictions-group-optional",level:4},{value:"3. Upload predictions",id:"3-upload-predictions",level:3}],l={toc:d};function c(e){let{components:n,...t}=e;return(0,a.kt)("wrapper",(0,o.Z)({},l,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,"In this example, we'll walk you through how to upload predictions using our API into an already existing dataset."),(0,a.kt)("p",null,"Before you begin: See ",(0,a.kt)("a",{parentName:"p",href:"./introduction#prerequisites"},"Prerequisites")," and learn about\nthe ",(0,a.kt)("a",{parentName:"p",href:"./prediction-format"},"prediction format"),"."),(0,a.kt)("h2",{id:"steps"},"Steps"),(0,a.kt)("p",null,"Create a new python file and import the following libraries:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nfrom kognic.auth.requests.auth_session import RequestsAuthSession\n\nbase_url = "https://dataset.app.kognic.com/v1/"\nclient = RequestsAuthSession()\n')),(0,a.kt)("h3",{id:"1-get-the-uuid-of-the-dataset"},"1. Get the UUID of the dataset"),(0,a.kt)("p",null,"You can either access the tool and copy the UUID following ",(0,a.kt)("inlineCode",{parentName:"p"},"dataset/")," in the URL, or utilize the datasets endpoint to\nget the uuid of the dataset:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'client.session.get(base_url + "datasets")\n')),(0,a.kt)("h3",{id:"2-get-the-uuid-of-an-existing-predictions-group-or-create-a-new-one"},"2. Get the UUID of an existing predictions group or create a new one"),(0,a.kt)("h4",{id:"2a-get-the-uuid-of-an-existing-predictions-group"},"2.a Get the UUID of an existing predictions group"),(0,a.kt)("p",null,"In order to upload predictions, a prediction group needs to exist. Predictions can be organized into groups for any\npurpose imaginable. The UUID of an existing prediction group can be found in the URL after ",(0,a.kt)("inlineCode",{parentName:"p"},"predictions/")," or by using\nthe endpoint"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'client.session.get(base_url + f"/datasets/{datasetUuid}/predictions-groups")\n')),(0,a.kt)("h4",{id:"2b-creating-a-predictions-group-optional"},"2.b Creating a predictions group (optional)"),(0,a.kt)("p",null,"For datasets not containing segmentation tasks, a new prediction group is created using the following code snippet"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'path = base_url + f"/datasets/{datasetUuid}/predictions-groups"\nbody = {"name": "My predictions group", "description": "A description of my new predictions group"}\ntry:\n    response = client.session.post(path, json=body)\n    response.raise_for_status()\n    response_json = response.json()\n    print(f"Created predictions group with uuid {response_json[\'data\']}")\nexcept requests.exceptions.RequestException as e:\n    msg = e.response.text\n    print(f"Request error: {e}. {msg}")\n')),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Special case: Segmentation datasets")),(0,a.kt)("p",null,"Predictions groups connected to segmentation datasets require one extra parameter called ",(0,a.kt)("inlineCode",{parentName:"p"},"classMapping"),". The mapping is used when\ncalculating disagreement between predictions and annotations and will impact the sorting as well as how disagreements appear in the gallery.\nThe ",(0,a.kt)("inlineCode",{parentName:"p"},"classMapping")," parameter is a list of dictionaries, where each dictionary contains the keys ",(0,a.kt)("inlineCode",{parentName:"p"},"annotated")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"predicted"),". The ",(0,a.kt)("inlineCode",{parentName:"p"},"annotated"),"\nkey is the class name in the annotations, and the ",(0,a.kt)("inlineCode",{parentName:"p"},"predicted")," key is the class name in the predictions.\n",(0,a.kt)("inlineCode",{parentName:"p"},'{"annotated": "oak", "predicted": "tree"}')," if you have annotated different species of trees, but only predict wether it is a tree or not."),(0,a.kt)("p",null,"All class names in the predictions and the annotations must be present in the class mappings, even if they don't need to be mapped. In the\nannotations, non-segmented areas are labeled with the class name ",(0,a.kt)("inlineCode",{parentName:"p"},"_background"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'example_body = {\n    "name": "My predictions group",\n    "description": "A description of my new predictions group",\n    "classMapping": [\n        {"annotated": "oak", "predicted": "tree"},\n        {"annotated": "_background", "predicted": "not_tree"},\n        {"annotated": "only_in_annotations"}\n    ]\n}\n')),(0,a.kt)("h3",{id:"3-upload-predictions"},"3. Upload predictions"),(0,a.kt)("p",null,"For a small amount of predictions, synchronous calls might work"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'import requests\n\nfrom kognic.auth.requests.auth_session import RequestsAuthSession\n\nbase_url = "https://dataset.app.kognic.com/v1/"\nclient = RequestsAuthSession()\n\npredictions_group_uuid = "..."\nopenlabel_content = {"openlabel": ...}\ndata = {\n    "sceneUuid": "...",\n    "openlabelContent": openlabel_content,\n}\n\ntry:\n    response = client.session.post(\n        base_url + f"predictions-groups/{predictions_group_uuid}/predictions",\n        json=data\n    )\n    response.raise_for_status()\n    response_json = response.json()\n    print(f"Created prediction with uuid {response_json[\'data\']}")\nexcept requests.exceptions.RequestException as e:\n    msg = e.response.text\n    print(f"Request error: {e}. {msg}")\n')),(0,a.kt)("p",null,"For larger amounts of predictions, asynchronous calls are recommended. The following example uses the async client from\nthe ",(0,a.kt)("inlineCode",{parentName:"p"},"kognic-auth")," library to make 100 asynchronous calls:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'import asyncio\n\nfrom kognic.auth.httpx.async_client import HttpxAuthAsyncClient\n\nbase_url = "https://dataset.app.kognic.com/v1/"\npredictions_group_uuid = "..."\nurl = base_url + f"predictions-groups/{predictions_group_uuid}/predictions"\nopenlabel_content = {"openlabel": ...}\n\nMAX_CONNECTIONS = 10\n\n\nasync def upload_prediction(payload, session, sem):\n    async with sem:\n        response = await session.post(url, json=payload)\n        response.raise_for_status()\n        return response.json().get("data")\n\n\nasync def main(n_runs: int):\n    client = HttpxAuthAsyncClient()\n    session = await client.session\n\n    sem = asyncio.Semaphore(MAX_CONNECTIONS)\n    tasks = []\n    for i in range(n_runs):\n        payload = {"sceneUuid": "...", "openlabelContent": openlabel_content}\n        task = upload_prediction(payload, session, sem)\n        tasks.append(task)\n\n    responses = await asyncio.gather(*tasks)\n    await session.aclose()\n\n    print(responses)\n\n\nif __name__ == \'__main__\':\n    asyncio.run(main(100))\n')),(0,a.kt)("p",null,"Setting ",(0,a.kt)("inlineCode",{parentName:"p"},"MAX_CONNECTIONS")," to something bigger than 10 might not work and is not recommended."))}c.isMDXComponent=!0}}]);